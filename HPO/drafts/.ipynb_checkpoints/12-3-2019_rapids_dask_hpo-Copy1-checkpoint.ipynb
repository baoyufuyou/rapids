{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Scaling XGBoost Hyper-Parameter Optimization</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/swarm.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach highest performance in classification tasks (i.e., supervised learning ), it is best practice to build an ensemble of champion models. \n",
    "\n",
    "Each member of the ensemble is a winner of a search over many models of its kind with altered hyper-parameters.\n",
    "\n",
    "In this notebook, we build a harness for running such a [hyper-parameter] search to demonstrate the accuracy benefits while exploring performance as we scale within and accross GPU nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np; import pandas as pd; import cudf\n",
    "import cuml; import xgboost; from xgboost import plot_tree\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "import time; import copy \n",
    "\n",
    "import data_utils\n",
    "import swarm\n",
    "import visualization as viz\n",
    "\n",
    "# reload library modules/code without a kernel restart\n",
    "import importlib; importlib.reload( swarm ); importlib.reload( data_utils ); importlib.reload( viz);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> In this notebook you can try different hyper-parameter search methods using synthetic or real data. </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/datasets.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Optional ] Synthetic Dataset Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploreSyntheticDataFlag = False\n",
    "if exploreSyntheticDataFlag:\n",
    "    viz.visualize_synthetic_data_variants('whirl', nSamples = 10000, sdevScales = [ .3, .3, .3], nCoils = [2, 4, 6, 12])\n",
    "    viz.visualize_synthetic_data_variants('helix', nSamples = 10000, sdevScales = [ .1, .1, .1], nCoils = [2, 4, 6, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import / Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy.asfortranarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = data_utils.Dataset('fashion-mnist')\n",
    "# dataset = data_utils.Dataset('airline', nSamples = 1000000)\n",
    "dataset = data_utils.Dataset('synthetic', coilType = 'whirl', coilDensity=15, nSamples=1000000, shuffleFlag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL [ split & normalize ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'trainData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-c729f2455b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'trainData'"
     ]
    }
   ],
   "source": [
    "dataset.trainData.shape, dataset.testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting SYNTHETIC dataset, original shape: (1000000, 3)\n",
      " > plotting subset of 100000 samples -- 10.00% of total, adjust via maxSamplesToPlot \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c9d43851e7401ca208ce9206a284bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.plot_data( dataset.data, dataset.labels, dataset.datasetName )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_middle_to_test_set ( data, labels, percentTrain = .8, targetDim ='x', percentTrainFromTestRegion = .015 ):\n",
    "    \n",
    "    dataSpan = ( data[targetDim].max() - data[targetDim].min() )\n",
    "    dataMiddle = dataSpan/2.\n",
    "    testDataSpan = dataSpan*(1-percentTrain)\n",
    "    dataMiddle + testDataSpan/2.\n",
    "    \n",
    "    print(f'assigning middle [ along dim: {targetDim} ] as test set')\n",
    "    testData = data[data[targetDim].ge( middle - extent )]\n",
    "    testData = testData[testData[targetDim].le( middle + extent )]\n",
    "    trainData = data[data[targetDim].ne( testData[targetDim]) ]\n",
    "    testLabels = labels.iloc[testData.index]\n",
    "    trainLabels = labels.iloc[trainData.index]\n",
    "\n",
    "    samplesToSwap = int( trainData.shape[0] * percentTrainFromTestRegion )\n",
    "    print(f'swapping {samplesToSwap} samples')\n",
    "    if samplesToSwap > 0:\n",
    "        # swap data\n",
    "        for iColumn in trainData.columns:\n",
    "            tempBuffer = trainData[iColumn][0:samplesToSwap].copy()\n",
    "            trainData[iColumn][0:samplesToSwap] = testData[iColumn][0:samplesToSwap] \n",
    "            testData[iColumn][0:samplesToSwap] = tempBuffer\n",
    "            \n",
    "        # swap labels\n",
    "        assert(labels.columns[0] == 'labels')\n",
    "        tempBuffer = trainLabels['labels'][0:samplesToSwap].copy()\n",
    "        trainLabels['labels'][0:samplesToSwap] = testLabels['labels'][0:samplesToSwap] \n",
    "        testLabels['labels'][0:samplesToSwap] = tempBuffer            \n",
    "\n",
    "    return trainData, trainLabels, testData, testLabels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigning middle [ along dim: x ] as test set\n",
      "swapping 11256 samples\n",
      "CPU times: user 93.3 ms, sys: 36.4 ms, total: 130 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainData, trainLabels, testData, testLabels = assign_middle_to_test_set( dataset.data, dataset.labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750444, 3)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creating a problem worthy of HPO\n",
    "show typical\n",
    "run model\n",
    "\n",
    "show hard\n",
    "run model\n",
    "\n",
    "hpo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b79d1d1c8134cf1b9f3d1120fd5a4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure(width=800, height=800)\n",
    "\n",
    "\n",
    "#xyz = trainData.as_matrix()\n",
    "#ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='#babab', marker = 'sphere', size = 1.25)\n",
    "\n",
    "xyz = trainData[trainLabels.labels.eq(1)].as_matrix()\n",
    "ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='#8735fb', marker = 'sphere', size = 1)\n",
    "\n",
    "xyz = trainData[trainLabels.labels.eq(0)].as_matrix()\n",
    "ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='green', marker = 'sphere', size = 1)\n",
    "\n",
    "xyz = testData.as_matrix()\n",
    "ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='lightgray', marker = 'sphere', size = 2.75)\n",
    "\n",
    "\n",
    "#ipv.pylab.squarelim()\n",
    "#ipv.ylim(-12,12)\n",
    "#ipv.zlim(-12,12)\n",
    "ipv.xlim( ipv.gcf().xlim[0], ipv.gcf().xlim[1])\n",
    "ipv.ylim( ipv.gcf().ylim[0]-5, ipv.gcf().ylim[1]+5)\n",
    "ipv.zlim( ipv.gcf().zlim[0]-5, ipv.gcf().zlim[1]+5)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 26.1 ms, total: 1.54 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dd = trainData.iloc[::10,:]\n",
    "dl = trainLabels.iloc[::10]\n",
    "l1 = dd[dl.labels.eq(1)].as_matrix()\n",
    "l2 = dd[dl.labels.eq(0)].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 ms, sys: 7.93 ms, total: 44.3 ms\n",
      "Wall time: 45.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dd = trainData\n",
    "dl = trainLabels\n",
    "l1 = dd[dl.labels.eq(1)].as_matrix()\n",
    "l2 = dd[dl.labels.eq(0)].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375417, 3)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatSlider, ColorPicker, VBox, jslink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0589c2e29a4cfa8595653a5ced5dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure(width=800, height=800)\n",
    "#xyz = trainData.as_matrix()\n",
    "#ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='#babab', marker = 'sphere', size = 1.25)\n",
    "\n",
    "\n",
    "xyz = trainData[trainLabels.labels.eq(1)].as_matrix()\n",
    "ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='#8735fb', marker = 'sphere', size = 1)\n",
    "\n",
    "xyz = trainData[trainLabels.labels.eq(0)].as_matrix()\n",
    "ipv.scatter(xyz[:,0], xyz[:,1], xyz[:,2], color='green', marker = 'sphere', size = 1)\n",
    "\n",
    "xyz = testData.as_matrix()\n",
    "testDataScatter = ipv.scatter( xyz[:,0], xyz[:,1], xyz[:,2], color='lightgray', marker = 'sphere', size = 1, \n",
    "                               selected=np.arange(xyz.shape[0]), size_selected=1, color_selected='lightgray')\n",
    "\n",
    "size_selected = FloatSlider(min=0, max=5, step=0.1)\n",
    "jslink((testDataScatter, 'size_selected'), (size_selected, 'value'))\n",
    "color_selected = ColorPicker()\n",
    "jslink((testDataScatter, 'color_selected'), (color_selected, 'value'))\n",
    "#ipv.pylab.squarelim()\n",
    "#ipv.ylim(-12,12)\n",
    "#ipv.zlim(-12,12)\n",
    "ipv.xlim( ipv.gcf().xlim[0], ipv.gcf().xlim[1])\n",
    "ipv.ylim( ipv.gcf().ylim[0]-5, ipv.gcf().ylim[1]+5)\n",
    "ipv.zlim( ipv.gcf().zlim[0]-5, ipv.gcf().zlim[1]+5)\n",
    "#ipv.show()\n",
    "VBox([ipv.gcc(), size_selected, color_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz =ipv.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.0, 12.0)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipv.ylim( ipv.gcf().ylim[0]-5, ipv.gcf().ylim[1]+5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting SYNTHETIC dataset, original shape: (5000, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabe40576af74d68ba3d9dafad2c06dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.plot_data( dataset.data.iloc[0::2,:], dataset.labels.iloc[0::2,:], dataset.datasetName )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import delayed\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from dask.distributed import worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster( ip = '', n_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client( cluster, asynchronous = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define HPO XGBoost Search Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramRanges = { 0: ['max_depth', 3, 20, 'int'],\n",
    "                1: ['learning_rate', .001, 1, 'float'],\n",
    "                2: ['gamma', 0, 2, 'float'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "| method name | &nbsp;&nbsp;&nbsp; performance | &nbsp;&nbsp;&nbsp; search duration  |\n",
    "|-----------------------|-----------------|------------------|\n",
    "| random-search         | &nbsp;&nbsp;&nbsp; worst | &nbsp;&nbsp;&nbsp; slow    |\n",
    "| particle-search [1]      | &nbsp;&nbsp;&nbsp; good  | &nbsp;&nbsp;&nbsp; fast    |\n",
    "| async-particle-search | &nbsp;&nbsp;&nbsp; best  | &nbsp;&nbsp;&nbsp; fastest |\n",
    "\n",
    "<center>[1] https://en.wikipedia.org/wiki/Particle_swarm_optimization#Algorithm</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Params [ nParticles & nEpochs ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync vs Async [ Dask Task Stream ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/sync_vs_async.png' width='1000px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Perf [ <- ]\n",
    "You'll have need to have launched the container w Port Open\n",
    "Connect via [ the http:// is important]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "nTrees = 100\n",
    "paramsGPU = { 'tree_method': 'gpu_hist',\n",
    "              'max_depth': 6,\n",
    "              'objective': 'binary:hinge'\n",
    "            }\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "trainDMatrix = xgboost.DMatrix( data = dataset.trainData, label = dataset.trainLabels )\n",
    "trainedModelGPU = xgboost.train( dtrain = trainDMatrix, params = paramsGPU, num_boost_round = nTrees )\n",
    "\n",
    "testDMatrix = xgboost.DMatrix( data = dataset.testData, label = dataset.testLabels )\n",
    "predictionsGPU = trainedModelGPU.predict( testDMatrix ).astype(int)\n",
    "\n",
    "trainAccuracy = 1 - float( trainedModelGPU.eval(trainDMatrix).split(':')[1] )\n",
    "testAccuracy = 1 - float( trainedModelGPU.eval(testDMatrix).split(':')[1] )   \n",
    "\n",
    "elapsedTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{paramsGPU}, {nTrees}')\n",
    "print(f'train accuracy: {trainAccuracy} \\ntest accuracy: {testAccuracy} \\ntrained in {elapsedTime:0.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color = '#ffb500'> Synchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncSwarm = swarm.SyncSwarm( client, dataset, paramRanges, nParticles = 16, nEpochs = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#ffb500'> Synchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( syncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( syncSwarm, topN = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( syncSwarm, syncSwarm.paramRanges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color='#7400ff'> Asynchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncSwarm = swarm.AsyncSwarm( client, dataset, paramRanges, nParticles = 1, nEpochs = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#7400ff'> Asynchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( asyncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( asyncSwarm, topN = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( asyncSwarm, asyncSwarm.paramRanges )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color='#666666'> Random Search </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomAsyncSwarm = swarm.RandomSearchAsync ( client, dataset, paramRanges, nEpochs = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomAsyncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#666666'> Random Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( randomAsyncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( randomAsyncSwarm, topN = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( randomAsyncSwarm, randomAsyncSwarm.paramRanges )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if syncSwarm.globalBest['accuracy'] > asyncSwarm.globalBest['accuracy']:\n",
    "    swarm = syncSwarm\n",
    "else:\n",
    "    swarm = asyncSwarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParams = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'random_state': 0, \n",
    "    'max_depth': int(swarm.globalBest['params'][0]),\n",
    "    'learning_rate': swarm.globalBest['params'][1],\n",
    "    'gamma': swarm.globalBest['params'][2]\n",
    "}\n",
    "    \n",
    "bestParams['objective'] = dataset.trainObjective[0]\n",
    "if dataset.trainObjective[1] is not None: \n",
    "    bestParams['num_class'] = dataset.trainObjective[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainDMatrix = xgboost.DMatrix( data = dataset.trainData, label = dataset.trainLabels )\n",
    "testDMatrix = xgboost.DMatrix( data = dataset.testData, label = dataset.testLabels )\n",
    "trainedModelGPU = xgboost.train( dtrain = trainDMatrix, evals = [(testDMatrix, 'test')], params = bestParams,\n",
    "                                 num_boost_round = swarm.globalBest['nTrees'], verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "trainedModelGPU.save_model('xgb.model.hpo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import ForestInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ForestInference.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trainOb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = ForestInference.load( filename='xgb.model.hpo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = ForestInference.load( filename='xgb.model.hpo',\n",
    "                           algo='BATCH_TREE_REORG',\n",
    "                           output_class=True,\n",
    "                           threshold=0,\n",
    "                           model_type='xgboost' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type( dataset.testData )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.testData.as_gpu_matrix(order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iColumn in dataset.testData.columns:    \n",
    "    dataset.testData[iColumn] = dataset.testData[iColumn].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.testData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainedModelGPU.predict( testDMatrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filPredictions = fm.predict ( dataset.testData, \n",
    "                              algo='BATCH_TREE_REORG', \n",
    "                              output_class=True, \n",
    "                              threshold=0, \n",
    "                              model_type='xgboost' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudf.Series(filPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# perform prediction on the model loaded from path\n",
    "fil_preds = fm.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with trained model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = trainedModelGPU.eval(testDMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataPerf = 1 - float( predictions.split(':')[1] )\n",
    "print(f'accuracy: {testDataPerf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Up Results [ DGX-2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/synthetic_async.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async Scaling > Sync Scaling > Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.osgeo.cn/matplotlib/gallery/lines_bars_and_markers/timeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work / Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "larger than single GPU memory datasets - dask_cudf + [ dask_xgboost or xgboost.dask ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ Generate a classification dataset on GPU ](#data-load) (e.g., double helix, unwinding helix/whirl )\n",
    "\n",
    "2. [ ETL - process/prepare data for model training ](#ETL) (e.g., scale, split, augment )   \n",
    "    \n",
    "3. [ Define HPO Strategy ](#define-hpo)\n",
    "\n",
    "4. [ Create Compute Cluster ](#compute-cluster)\n",
    "   > LocalCUDACluster or KubeCluster\n",
    "      \n",
    "5. [ Define Seach ](#define-search)\n",
    "\n",
    "6. [ Run ASYNC Particle Swarm ](#run-async-PSO)\n",
    "\n",
    "7. [ Run Classic Particle Swarm ](#run-classic-PSO)\n",
    "\n",
    "8. [ Run Random Search Baseline ](#run-random-search)\n",
    "\n",
    "9. [ Summary ](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Choices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is able to make several key choices in running this notebook. They are as follows:\n",
    "\n",
    "1. [ Dataset ]()\n",
    "2. [ Compute Scaling Strategy - Scale-Up, Scale-Out ]()\n",
    "3. [ XGBoost Parameter Search Range ]()\n",
    "\n",
    "4. [ Particle Swarm Type ]()\n",
    "   * Synchronous\n",
    "   * Asynchronous\n",
    "   * Random Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
