{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cupy.random.normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Scaling XGBoost Hyper-Parameter Optimization</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/swarm.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach highest performance in classification tasks (i.e., supervised learning ), it is best practice to build an ensemble of champion models. \n",
    "\n",
    "Each member of the ensemble is a winner of a search over many models of its kind with altered hyper-parameters.\n",
    "\n",
    "In this notebook, we build a harness for running such a [hyper-parameter] search to demonstrate the accuracy benefits while exploring performance as we scale within and accross GPU nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np; import pandas as pd; import cudf\n",
    "import cuml; import xgboost; from xgboost import plot_tree\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "import time; import copy \n",
    "\n",
    "import data_utils\n",
    "import swarm\n",
    "import visualization as viz\n",
    "\n",
    "# reload library modules/code without a kernel restart\n",
    "import importlib; importlib.reload( swarm ); importlib.reload( data_utils ); importlib.reload( viz);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> In this notebook you can try different hyper-parameter search methods using synthetic or real data. </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/datasets.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Optional ] Synthetic Dataset Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploreSyntheticDataFlag = True\n",
    "if exploreSyntheticDataFlag:\n",
    "    viz.visualize_synthetic_data_variants('whirl', nSamples = 10000, sdevScales = [ .3, .3, .3], nCoils = [2, 4, 6, 12])\n",
    "    viz.visualize_synthetic_data_variants('helix', nSamples = 10000, sdevScales = [ .1, .1, .1], nCoils = [2, 4, 6, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import / Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?data_utils.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading AIRLINE from local copy [ via pandas reader ]\n",
      "rescaling data\n",
      "rescaling data\n"
     ]
    }
   ],
   "source": [
    "# dataset = data_utils.Dataset('fashion-mnist')\n",
    "dataset = data_utils.Dataset('airline', nSamples = 1000000)\n",
    "#dataset = data_utils.Dataset('synthetic', coilType = 'whirl', coilDensity=20, nCoordinates = 1000, nSamples=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL [ split & normalize ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trainData.shape, dataset.testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_data( dataset.data, dataset.labels, dataset.datasetName )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_data( dataset.testData, dataset.testLabels, dataset.datasetName )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask import delayed\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from dask.distributed import worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster( ip = '', n_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client( cluster, asynchronous = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define HPO XGBoost Search Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramRanges = { 0: ['max_depth', 3, 20, 'int'],\n",
    "                1: ['learning_rate', .001, 1, 'float'],\n",
    "                2: ['gamma', 0, 2, 'float'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "| method name | &nbsp;&nbsp;&nbsp; performance | &nbsp;&nbsp;&nbsp; search duration  |\n",
    "|-----------------------|-----------------|------------------|\n",
    "| random-search         | &nbsp;&nbsp;&nbsp; worst | &nbsp;&nbsp;&nbsp; slow    |\n",
    "| particle-search [1]      | &nbsp;&nbsp;&nbsp; good  | &nbsp;&nbsp;&nbsp; fast    |\n",
    "| async-particle-search | &nbsp;&nbsp;&nbsp; best  | &nbsp;&nbsp;&nbsp; fastest |\n",
    "\n",
    "<center>[1] https://en.wikipedia.org/wiki/Particle_swarm_optimization#Algorithm</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Params [ nParticles & nEpochs ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync vs Async [ Dask Task Stream ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/sync_vs_async.png' width='1000px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Perf [ <- ]\n",
    "You'll have need to have launched the container w Port Open\n",
    "Connect via [ the http:// is important]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "nTrees = 100\n",
    "paramsGPU = { 'tree_method': 'gpu_hist',\n",
    "              'max_depth': 6,\n",
    "              'objective': 'binary:hinge'\n",
    "            }\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "trainDMatrix = xgboost.DMatrix( data = dataset.trainData, label = dataset.trainLabels )\n",
    "trainedModelGPU = xgboost.train( dtrain = trainDMatrix, params = paramsGPU, num_boost_round = nTrees )\n",
    "\n",
    "testDMatrix = xgboost.DMatrix( data = dataset.testData, label = dataset.testLabels )\n",
    "predictionsGPU = trainedModelGPU.predict( testDMatrix ).astype(int)\n",
    "\n",
    "trainAccuracy = 1 - float( trainedModelGPU.eval(trainDMatrix).split(':')[1] )\n",
    "testAccuracy = 1 - float( trainedModelGPU.eval(testDMatrix).split(':')[1] )   \n",
    "\n",
    "elapsedTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{paramsGPU}, {nTrees}')\n",
    "print(f'train accuracy: {trainAccuracy} \\ntest accuracy: {testAccuracy} \\ntrained in {elapsedTime:0.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color = '#ffb500'> Synchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncSwarm = swarm.SyncSwarm( client, dataset, paramRanges, nParticles = 16, nEpochs = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#ffb500'> Synchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( syncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( syncSwarm, topN = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( syncSwarm, syncSwarm.paramRanges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color='#7400ff'> Asynchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncSwarm = swarm.AsyncSwarm( client, dataset, paramRanges, nParticles = 1, nEpochs = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#7400ff'> Asynchronous Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( asyncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( asyncSwarm, topN = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( asyncSwarm, asyncSwarm.paramRanges )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HPO - <font color='#666666'> Random Search </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomAsyncSwarm = swarm.RandomSearchAsync ( client, dataset, paramRanges, nEpochs = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomAsyncSwarm.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize <font color='#666666'> Random Swarm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_particle_evals( randomAsyncSwarm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_particle_trails( randomAsyncSwarm, topN = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.viz_swarm( randomAsyncSwarm, randomAsyncSwarm.paramRanges )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine best swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if syncSwarm.globalBest['accuracy'] > asyncSwarm.globalBest['accuracy']:\n",
    "    swarm = syncSwarm\n",
    "else:\n",
    "    swarm = asyncSwarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParams = {\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'random_state': 0, \n",
    "    'max_depth': int(swarm.globalBest['params'][0]),\n",
    "    'learning_rate': swarm.globalBest['params'][1],\n",
    "    'gamma': swarm.globalBest['params'][2]\n",
    "}\n",
    "    \n",
    "bestParams['objective'] = dataset.trainObjective[0]\n",
    "if dataset.trainObjective[1] is not None: \n",
    "    bestParams['num_class'] = dataset.trainObjective[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainDMatrix = xgboost.DMatrix( data = dataset.trainData, label = dataset.trainLabels )\n",
    "testDMatrix = xgboost.DMatrix( data = dataset.testData, label = dataset.testLabels )\n",
    "trainedModelGPU = xgboost.train( dtrain = trainDMatrix, evals = [(testDMatrix, 'test')], params = bestParams,\n",
    "                                 num_boost_round = swarm.globalBest['nTrees'], verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "trainedModelGPU.save_model('xgb.model.hpo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import ForestInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ForestInference.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trainOb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = ForestInference.load( filename='xgb.model.hpo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = ForestInference.load( filename='xgb.model.hpo',\n",
    "                           algo='BATCH_TREE_REORG',\n",
    "                           output_class=True,\n",
    "                           threshold=0,\n",
    "                           model_type='xgboost' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type( dataset.testData )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.testData.as_gpu_matrix(order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iColumn in dataset.testData.columns:    \n",
    "    dataset.testData[iColumn] = dataset.testData[iColumn].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.testData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainedModelGPU.predict( testDMatrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filPredictions = fm.predict ( dataset.testData, \n",
    "                              algo='BATCH_TREE_REORG', \n",
    "                              output_class=True, \n",
    "                              threshold=0, \n",
    "                              model_type='xgboost' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudf.Series(filPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# perform prediction on the model loaded from path\n",
    "fil_preds = fm.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with trained model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = trainedModelGPU.eval(testDMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataPerf = 1 - float( predictions.split(':')[1] )\n",
    "print(f'accuracy: {testDataPerf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Up Results [ DGX-2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/synthetic_async.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async Scaling > Sync Scaling > Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.osgeo.cn/matplotlib/gallery/lines_bars_and_markers/timeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work / Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "larger than single GPU memory datasets - dask_cudf + [ dask_xgboost or xgboost.dask ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ Generate a classification dataset on GPU ](#data-load) (e.g., double helix, unwinding helix/whirl )\n",
    "\n",
    "2. [ ETL - process/prepare data for model training ](#ETL) (e.g., scale, split, augment )   \n",
    "    \n",
    "3. [ Define HPO Strategy ](#define-hpo)\n",
    "\n",
    "4. [ Create Compute Cluster ](#compute-cluster)\n",
    "   > LocalCUDACluster or KubeCluster\n",
    "      \n",
    "5. [ Define Seach ](#define-search)\n",
    "\n",
    "6. [ Run ASYNC Particle Swarm ](#run-async-PSO)\n",
    "\n",
    "7. [ Run Classic Particle Swarm ](#run-classic-PSO)\n",
    "\n",
    "8. [ Run Random Search Baseline ](#run-random-search)\n",
    "\n",
    "9. [ Summary ](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Choices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is able to make several key choices in running this notebook. They are as follows:\n",
    "\n",
    "1. [ Dataset ]()\n",
    "2. [ Compute Scaling Strategy - Scale-Up, Scale-Out ]()\n",
    "3. [ XGBoost Parameter Search Range ]()\n",
    "\n",
    "4. [ Particle Swarm Type ]()\n",
    "   * Synchronous\n",
    "   * Asynchronous\n",
    "   * Random Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
