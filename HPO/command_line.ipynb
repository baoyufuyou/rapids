{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--coil_type COIL_TYPE] [--num_blobs NUM_BLOBS]\n",
      "               [--num_coordinates NUM_COORDINATES] [--sdev_scale SDEV_SCALE]\n",
      "               [--noise_scale NOISE_SCALE] [--coil_density COIL_DENSITY]\n",
      "               [--train_test_overlap TRAIN_TEST_OVERLAP]\n",
      "               [--num_timesteps NUM_TIMESTEPS] [--num_particles NUM_PARTICLES]\n",
      "               [--k8s] [--adapt] [--spec SPEC] [--num_gpus NUM_GPUS]\n",
      "               [--min_gpus MIN_GPUS]\n",
      "\n",
      "Perform hyper-parameter optimization using Dask\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --coil_type COIL_TYPE\n",
      "                        the type of coil to generate the data (default: helix)\n",
      "  --num_blobs NUM_BLOBS\n",
      "                        the number of blobs generated on the GPU (default:\n",
      "                        1000)\n",
      "  --num_coordinates NUM_COORDINATES\n",
      "                        the number of starting locations of each blob\n",
      "                        (default: 400)\n",
      "  --sdev_scale SDEV_SCALE\n",
      "                        standard deviation of normals used to generate data\n",
      "                        (default: 0.3)\n",
      "  --noise_scale NOISE_SCALE\n",
      "                        additional noise (default: 0.1)\n",
      "  --coil_density COIL_DENSITY\n",
      "                        how tight the coils are (default: 12.0)\n",
      "  --train_test_overlap TRAIN_TEST_OVERLAP\n",
      "                        percentage of train and test distribution that\n",
      "                        overlaps (default: 0.05)\n",
      "  --num_timesteps NUM_TIMESTEPS\n",
      "                        the number of timesteps to run HPO (default: 10)\n",
      "  --num_particles NUM_PARTICLES\n",
      "                        the number of particles in the swarm (default: 32)\n",
      "  --k8s                 use a KubeCluster instead of LocalCudaCluster\n",
      "                        (default: False)\n",
      "  --adapt               use adaptive scaling of k8s workers [min_gpus,\n",
      "                        num_gpus] (default: False)\n",
      "  --spec SPEC           the k8s worker_spec yaml file to use (default: None)\n",
      "  --num_gpus NUM_GPUS   the number of workers deployed or maximum workers when\n",
      "                        using K8S adaptive; each worker gets 1 GPU (default:\n",
      "                        1)\n",
      "  --min_gpus MIN_GPUS   the minimum number of workers when using adaptive\n",
      "                        scaling (default: 32)\n"
     ]
    }
   ],
   "source": [
    "!python main.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n",
      "Launching Local Dask cluster with 4 GPUs\n",
      "<Client: scheduler='tcp://10.233.69.185:43317' processes=4 cores=4>\n",
      "LocalCUDACluster('tcp://10.233.69.185:43317', workers=4, nthreads=4)\n",
      "generating blobs; # points = 400000\n",
      "generating blobs; # points = 400000\n",
      "time to generate data on GPU = 1.7928249835968018\n",
      "splitting data into training and test set\n",
      "rescaling data\n",
      "rescaling data\n",
      "@ hpo timestep : 0, best accuracy is 0.9512125\n",
      "\t updating best GLOBAL accuracy\n",
      "@ hpo timestep : 1, best accuracy is 0.9527\n",
      "\t updating best GLOBAL accuracy\n",
      "@ hpo timestep : 2, best accuracy is 0.9515125\n",
      "@ hpo timestep : 3, best accuracy is 0.94855\n",
      "@ hpo timestep : 4, best accuracy is 0.951225\n",
      "@ hpo timestep : 5, best accuracy is 0.951975\n",
      "@ hpo timestep : 6, best accuracy is 0.952725\n",
      "\t updating best GLOBAL accuracy\n",
      "@ hpo timestep : 7, best accuracy is 0.9510125\n",
      "@ hpo timestep : 8, best accuracy is 0.9502375\n",
      "@ hpo timestep : 9, best accuracy is 0.9502375\n",
      "highest accuracy               :  0.952725 \n",
      "   @ timestep 6, particle 17 \n",
      "\n",
      "best model tree depth          :  5.0 \n",
      "best model learning rate       :  0.8335521669442962 \n",
      "best model regularization      :  0.11902468106903752 \n",
      "best model num boosting rounds :  49 \n",
      "elapsed time : 145.66159868240356\n"
     ]
    }
   ],
   "source": [
    "!python main.py --num_gpus 4 --num_timesteps 10 --coil_type 'helix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --k8s --num_gpus 2 \\\n",
    "                --num_timesteps 10 --coil_type 'helix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --k8s --adapt --num_gpus 4 --min_gpus 1 \\\n",
    "                --num_timesteps 10 --coil_type 'helix'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
